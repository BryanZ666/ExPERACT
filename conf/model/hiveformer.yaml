# @package _global_

model:
  train_lm: True

 
MODEL:
  model_class: 'TransformerUNet'

  unet: True
  num_tasks: null
  use_instr_embed: 'all' # none, avg, last, all
  instr_embed_size: 512
  max_steps: 20

  num_layers: 4
  hidden_size: 32
  gripper_channel: 'attn'

  num_trans_layers: 1
  nhead: 8
  txt_attn_type: 'cross' # self, cross 
  num_cams: 3
  latent_im_size: (8, 8)
  quat_input: 'concat' #
